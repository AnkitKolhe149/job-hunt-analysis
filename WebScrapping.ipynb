{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dda09e1e-8f2d-48f2-95a3-80613e5522b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8251b79f-dbf7-4c2f-b756-cc26af7b907c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.25.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (2024.7.4)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.17.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "561b9209-b3e3-421a-a5c1-b6dbe3146091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->webdriver-manager) (2024.7.4)\n",
      "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b94d53-ba4d-43b5-be5e-6b4e28156cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: selenium in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.25.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio~=0.17->selenium) (1.17.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\sjkad\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 selenium pandas webdriver-manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f51fce-ab55-4c19-b171-6dc4869d368b",
   "metadata": {},
   "source": [
    "## Job Posts using WEB SCRAPPING\n",
    "## Here we used different url's for different pages (manual method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d18ed5-7715-4e8a-b1d8-e5bbf1271de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Job Title, Company, Location]\n",
      "Index: []\n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Extract job titles, company names, and locations\n",
    "job_titles = [title.text.strip() for title in soup.find_all('a', class_='jobLink')]\n",
    "company_names = [company.text.strip() for company in soup.find_all('div', class_='jobEmpolyerName')]\n",
    "locations = [location.text.strip() for location in soup.find_all('span', class_='subtle loc')]\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "print(\"Data saved to glassdoor_job_listings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fefd016e-027f-41cc-8dd3-40818bf79cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Titles Raw: []\n",
      "Company Names Raw: []\n",
      "Locations Raw: []\n",
      "Job Titles: []\n",
      "Company Names: []\n",
      "Locations: []\n",
      "Empty DataFrame\n",
      "Columns: [Job Title, Company, Location]\n",
      "Index: []\n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Print raw HTML for job titles, company names, and locations\n",
    "job_titles = soup.find_all('a', class_='jobLink')\n",
    "company_names = soup.find_all('div', class_='jobEmpolyerName')\n",
    "locations = soup.find_all('span', class_='subtle loc')\n",
    "\n",
    "print(\"Job Titles Raw:\", job_titles)\n",
    "print(\"Company Names Raw:\", company_names)\n",
    "print(\"Locations Raw:\", locations)\n",
    "\n",
    "# Process text from elements\n",
    "job_titles_text = [title.text.strip() for title in job_titles]\n",
    "company_names_text = [company.text.strip() for company in company_names]\n",
    "locations_text = [location.text.strip() for location in locations]\n",
    "\n",
    "print(\"Job Titles:\", job_titles_text)\n",
    "print(\"Company Names:\", company_names_text)\n",
    "print(\"Locations:\", locations_text)\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles_text), len(company_names_text), len(locations_text))\n",
    "\n",
    "job_titles_text = job_titles_text[:min_length]\n",
    "company_names_text = company_names_text[:min_length]\n",
    "locations_text = locations_text[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles_text,\n",
    "    'Company': company_names_text,\n",
    "    'Location': locations_text\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "print(\"Data saved to glassdoor_job_listings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2476fadb-a1c2-4fff-ba58-93c54dec7fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Titles: ['Data Scientist', 'NLP Project Manager', 'Data Scientist', 'Data Scientist - Junior (#40500)', 'Data Scientist', 'Data Scientist', 'Data Scientist, University Graduate, 2025', 'Data Scientist - immediate joiner', 'Data Scientist', 'Principal Data Analytics', 'Data Scientist', 'Data Scientist', 'Data Scientist Intern', 'Junior Data Scientist', 'Data Scientist', 'Data Science Intern', 'Junior Data Scientist', 'Data Scientist II', 'Data Scientist', 'Python Data Scientist', 'python data scientist', 'Data Scientist', 'Data Scientist Intern', 'LLM_Data Scientist/Data Analyst', 'Data Scientist', 'Data Scientist', 'Data Science & ML Intern', 'Data Scientist', 'Jr Data Scientist', 'Data Scientist']\n",
      "Company Names: ['Flipkart3.8', 'objectways', 'Blackcoffer (OPC) Pvt. Ltd4.1', 'Infocepts3.5', 'Smart Capital Center3.7', 'Laurate LLC', 'Google4.3', 'Nithminds Private limited', 'Accusaga', 'Zelis3.8', 'Datacorns LLC', 'HealthPlix Technologies', 'SoulPage IT Solutions4.5', 'Ray Business Technologies', 'Impresario Global', 'Ecowiser5.0', 'Cravita Technologies India4.4', 'Indeed4.0', 'Larsen & Toubro3.4', 'Act2hire', 'ACT2HIRE', 'Adhiran Infotech', 'Testcore Solutions', 'Excellent Opportunity', 'hireskills', 'Kinara Capital4.3', 'Trekato Pvt. Ltd.', 'Exponentia.ai4.6', 'Veracity Software4.1', 'Provenir Inc.2.9', 'Flipkart3.8']\n",
      "Locations: ['Bengaluru', 'Coimbatore', 'Remote', 'India', 'Remote', 'Remote', 'Bengaluru', 'Remote', 'India', 'Hyderābād', 'Remote', 'Bengaluru', 'Hyderābād', 'Hyderābād', 'Remote', 'Remote', 'India', 'Remote', 'Mumbai', 'Remote', 'Remote', 'Chennai', 'India', 'Remote', 'Mumbai', 'Bengaluru', 'Chennai', 'Mumbai', 'India', 'Bengaluru']\n",
      "Salaries: []\n",
      "Empty DataFrame\n",
      "Columns: [Job Title, Company, Location, Salary]\n",
      "Index: []\n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Extract job titles\n",
    "job_titles = [title.text.strip() for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y')]\n",
    "\n",
    "# Extract company names\n",
    "company_names = [company.text.strip() for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE')]\n",
    "\n",
    "# Extract locations\n",
    "locations = [location.text.strip() for location in soup.find_all('div', class_='JobCard_location__rCz3x')]\n",
    "\n",
    "# Extract salaries\n",
    "salaries = [salary.text.strip() for salary in soup.find_all('span', class_='JobCard_salaryEstimate__arV5J')]\n",
    "\n",
    "# Print extracted data for verification\n",
    "print(\"Job Titles:\", job_titles)\n",
    "print(\"Company Names:\", company_names)\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Salaries:\", salaries)\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "print(\"Data saved to glassdoor_job_listings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c94b600d-16a3-45bb-a281-1ed9e8d3d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Titles: ['Data Scientist', 'NLP Project Manager', 'Data Scientist', 'Data Scientist - Junior (#40500)', 'Data Scientist', 'Data Scientist', 'Data Scientist, University Graduate, 2025', 'Data Scientist - immediate joiner', 'Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist Intern', 'Junior Data Scientist', 'Data Scientist', 'Data Science Intern', 'Junior Data Scientist', 'Data Scientist II', 'Data Scientist', 'Python Data Scientist', 'Data Scientist', 'Data Scientist Intern', 'LLM_Data Scientist/Data Analyst', 'Data Scientist', 'Data Scientist', 'Data Science & ML Intern', 'Data Scientist', 'Jr Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Analyst']\n",
      "Company Names: ['Flipkart3.8', 'objectways', 'Blackcoffer (OPC) Pvt. Ltd4.1', 'Infocepts3.5', 'Smart Capital Center3.7', 'Laurate LLC', 'Google4.3', 'Nithminds Private limited', 'Accusaga', 'Datacorns LLC', 'HealthPlix Technologies', 'SoulPage IT Solutions4.5', 'Ray Business Technologies', 'Impresario Global', 'Ecowiser5.0', 'Cravita Technologies India4.4', 'Indeed4.0', 'Larsen & Toubro3.4', 'Act2hire', 'Adhiran Infotech', 'Testcore Solutions', 'Excellent Opportunity', 'hireskills', 'Kinara Capital4.3', 'Trekato Pvt. Ltd.', 'Exponentia.ai4.6', 'Veracity Software4.1', 'Provenir Inc.2.9', 'Great River Financial Services Inc (GRFS)', '11X Company', 'Flipkart3.8']\n",
      "Locations: ['Bengaluru', 'Coimbatore', 'Remote', 'India', 'Remote', 'Remote', 'Bengaluru', 'Remote', 'India', 'Remote', 'Bengaluru', 'Hyderābād', 'Hyderābād', 'Remote', 'Remote', 'India', 'Remote', 'Mumbai', 'Remote', 'Chennai', 'India', 'Remote', 'Mumbai', 'Bengaluru', 'Chennai', 'Mumbai', 'India', 'Bengaluru', 'India', 'Remote']\n",
      "Salaries: ['₹2L - ₹6L\\xa0(Glassdoor Est.)', '₹4L\\xa0(Employer Est.)', '₹10T\\xa0(Employer Est.)', '₹15L - ₹41L\\xa0(Employer Est.)', '₹7L - ₹12L\\xa0(Employer Est.)', '₹5L - ₹19L\\xa0(Employer Est.)', '₹10L - ₹12L\\xa0(Employer Est.)', '₹10L - ₹15L\\xa0(Employer Est.)', '₹3L - ₹4L\\xa0(Employer Est.)', '₹4L\\xa0(Employer Est.)', '₹12T - ₹18T\\xa0(Employer Est.)', '₹50L - ₹74L\\xa0(Employer Est.)', '₹15L - ₹30L\\xa0(Employer Est.)', '₹15L - ₹41L\\xa0(Employer Est.)', '₹6L - ₹18L\\xa0(Employer Est.)', '₹20T\\xa0(Employer Est.)', '₹14L - ₹41L\\xa0(Employer Est.)', '₹6L - ₹15L\\xa0(Employer Est.)', '₹7L - ₹10L\\xa0(Glassdoor Est.)', '₹8T - ₹10T\\xa0(Employer Est.)', '₹7L - ₹8L\\xa0(Glassdoor Est.)', '₹3L - ₹8L\\xa0(Glassdoor Est.)', '₹8L\\xa0(Employer Est.)', '₹8T - ₹10T\\xa0(Employer Est.)']\n",
      "                                    Job Title                        Company  \\\n",
      "0                              Data Scientist                    Flipkart3.8   \n",
      "1                         NLP Project Manager                     objectways   \n",
      "2                              Data Scientist  Blackcoffer (OPC) Pvt. Ltd4.1   \n",
      "3            Data Scientist - Junior (#40500)                   Infocepts3.5   \n",
      "4                              Data Scientist        Smart Capital Center3.7   \n",
      "5                              Data Scientist                    Laurate LLC   \n",
      "6   Data Scientist, University Graduate, 2025                      Google4.3   \n",
      "7           Data Scientist - immediate joiner      Nithminds Private limited   \n",
      "8                              Data Scientist                       Accusaga   \n",
      "9                              Data Scientist                  Datacorns LLC   \n",
      "10                             Data Scientist        HealthPlix Technologies   \n",
      "11                      Data Scientist Intern       SoulPage IT Solutions4.5   \n",
      "12                      Junior Data Scientist      Ray Business Technologies   \n",
      "13                             Data Scientist              Impresario Global   \n",
      "14                        Data Science Intern                    Ecowiser5.0   \n",
      "15                      Junior Data Scientist  Cravita Technologies India4.4   \n",
      "16                          Data Scientist II                      Indeed4.0   \n",
      "17                             Data Scientist             Larsen & Toubro3.4   \n",
      "18                      Python Data Scientist                       Act2hire   \n",
      "19                             Data Scientist               Adhiran Infotech   \n",
      "20                      Data Scientist Intern             Testcore Solutions   \n",
      "21            LLM_Data Scientist/Data Analyst          Excellent Opportunity   \n",
      "22                             Data Scientist                     hireskills   \n",
      "23                             Data Scientist              Kinara Capital4.3   \n",
      "\n",
      "      Location                       Salary  \n",
      "0    Bengaluru   ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1   Coimbatore          ₹4L (Employer Est.)  \n",
      "2       Remote         ₹10T (Employer Est.)  \n",
      "3        India  ₹15L - ₹41L (Employer Est.)  \n",
      "4       Remote   ₹7L - ₹12L (Employer Est.)  \n",
      "5       Remote   ₹5L - ₹19L (Employer Est.)  \n",
      "6    Bengaluru  ₹10L - ₹12L (Employer Est.)  \n",
      "7       Remote  ₹10L - ₹15L (Employer Est.)  \n",
      "8        India    ₹3L - ₹4L (Employer Est.)  \n",
      "9       Remote          ₹4L (Employer Est.)  \n",
      "10   Bengaluru  ₹12T - ₹18T (Employer Est.)  \n",
      "11   Hyderābād  ₹50L - ₹74L (Employer Est.)  \n",
      "12   Hyderābād  ₹15L - ₹30L (Employer Est.)  \n",
      "13      Remote  ₹15L - ₹41L (Employer Est.)  \n",
      "14      Remote   ₹6L - ₹18L (Employer Est.)  \n",
      "15       India         ₹20T (Employer Est.)  \n",
      "16      Remote  ₹14L - ₹41L (Employer Est.)  \n",
      "17      Mumbai   ₹6L - ₹15L (Employer Est.)  \n",
      "18      Remote  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "19     Chennai   ₹8T - ₹10T (Employer Est.)  \n",
      "20       India   ₹7L - ₹8L (Glassdoor Est.)  \n",
      "21      Remote   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "22      Mumbai          ₹8L (Employer Est.)  \n",
      "23   Bengaluru   ₹8T - ₹10T (Employer Est.)  \n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Extract job titles\n",
    "job_titles = [title.text.strip() for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y')]\n",
    "\n",
    "# Extract company names\n",
    "company_names = [company.text.strip() for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE')]\n",
    "\n",
    "# Extract locations\n",
    "locations = [location.text.strip() for location in soup.find_all('div', class_='JobCard_location__rCz3x')]\n",
    "\n",
    "# Extract salaries\n",
    "salaries = [salary.text.strip() for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J')]\n",
    "\n",
    "# Print extracted data for verification\n",
    "print(\"Job Titles:\", job_titles)\n",
    "print(\"Company Names:\", company_names)\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Salaries:\", salaries)\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "print(\"Data saved to glassdoor_job_listings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c27802a-74bc-4a8d-8599-5d5f3512fee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Titles: ['Data Scientist', 'NLP Project Manager', 'Data Scientist', 'Data Scientist - Junior (#40500)', 'Data Scientist', 'Data Scientist', 'Data Scientist, University Graduate, 2025', 'Data Scientist - immediate joiner', 'Data Scientist', 'Data Scientist', 'Data Scientist Intern', 'Junior Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Science Intern', 'Junior Data Scientist', 'Data Scientist II', 'Data Scientist', 'Python Data Scientist', 'Data Scientist', 'Data Scientist', 'Data Scientist Intern', 'LLM_Data Scientist/Data Analyst', 'Data Scientist', 'Data Scientist', 'Data Science & ML Intern', 'Data Scientist', 'Jr Data Scientist', 'Data Scientist', 'Data Scientist']\n",
      "Company Names: ['Flipkart3.8', 'objectways', 'Blackcoffer (OPC) Pvt. Ltd4.1', 'Infocepts3.5', 'Smart Capital Center3.7', 'Laurate LLC', 'Google4.3', 'Nithminds Private limited', 'Accusaga', 'Datacorns LLC', 'SoulPage IT Solutions4.5', 'Ray Business Technologies', 'Impresario Global', 'HealthPlix Technologies', 'Ecowiser5.0', 'Cravita Technologies India4.4', 'Indeed4.0', 'Larsen & Toubro3.4', 'Act2hire', 'ANZ Banking Group3.9', 'Adhiran Infotech', 'Testcore Solutions', 'Excellent Opportunity', 'hireskills', 'Kinara Capital4.3', 'Trekato Pvt. Ltd.', 'Exponentia.ai4.6', 'Veracity Software4.1', 'Provenir Inc.2.9', 'Great River Financial Services Inc (GRFS)', 'Flipkart3.8']\n",
      "Locations: ['Bengaluru', 'Coimbatore', 'Remote', 'India', 'Remote', 'Remote', 'Bengaluru', 'Remote', 'India', 'Remote', 'Hyderābād', 'Hyderābād', 'Remote', 'Bengaluru', 'Remote', 'India', 'Remote', 'Mumbai', 'Remote', 'Bengaluru', 'Chennai', 'India', 'Remote', 'Mumbai', 'Bengaluru', 'Chennai', 'Mumbai', 'India', 'Bengaluru', 'India']\n",
      "Salaries: ['₹2L - ₹6L (Glassdoor Est.)', '₹4L (Employer Est.)', '₹10T (Employer Est.)', '₹15L - ₹41L (Employer Est.)', '₹7L - ₹12L (Employer Est.)', '₹5L - ₹19L (Employer Est.)', '₹10L - ₹12L (Employer Est.)', '₹3L - ₹4L (Employer Est.)', '₹4L (Employer Est.)', '₹10L - ₹15L (Employer Est.)', '₹12T - ₹18T (Employer Est.)', '₹50L - ₹74L (Employer Est.)', '₹15L - ₹30L (Employer Est.)', '₹15L - ₹41L (Employer Est.)', '₹3L - ₹10L (Glassdoor Est.)', '₹6L - ₹18L (Employer Est.)', '₹20T (Employer Est.)', '₹14L - ₹41L (Employer Est.)', '₹6L - ₹15L (Employer Est.)', '₹7L - ₹10L (Glassdoor Est.)', '₹8T - ₹10T (Employer Est.)', '₹7L - ₹8L (Glassdoor Est.)', '₹3L - ₹8L (Glassdoor Est.)', '₹8L (Employer Est.)']\n",
      "                                    Job Title                        Company  \\\n",
      "0                              Data Scientist                    Flipkart3.8   \n",
      "1                         NLP Project Manager                     objectways   \n",
      "2                              Data Scientist  Blackcoffer (OPC) Pvt. Ltd4.1   \n",
      "3            Data Scientist - Junior (#40500)                   Infocepts3.5   \n",
      "4                              Data Scientist        Smart Capital Center3.7   \n",
      "5                              Data Scientist                    Laurate LLC   \n",
      "6   Data Scientist, University Graduate, 2025                      Google4.3   \n",
      "7           Data Scientist - immediate joiner      Nithminds Private limited   \n",
      "8                              Data Scientist                       Accusaga   \n",
      "9                              Data Scientist                  Datacorns LLC   \n",
      "10                      Data Scientist Intern       SoulPage IT Solutions4.5   \n",
      "11                      Junior Data Scientist      Ray Business Technologies   \n",
      "12                             Data Scientist              Impresario Global   \n",
      "13                             Data Scientist        HealthPlix Technologies   \n",
      "14                        Data Science Intern                    Ecowiser5.0   \n",
      "15                      Junior Data Scientist  Cravita Technologies India4.4   \n",
      "16                          Data Scientist II                      Indeed4.0   \n",
      "17                             Data Scientist             Larsen & Toubro3.4   \n",
      "18                      Python Data Scientist                       Act2hire   \n",
      "19                             Data Scientist           ANZ Banking Group3.9   \n",
      "20                             Data Scientist               Adhiran Infotech   \n",
      "21                      Data Scientist Intern             Testcore Solutions   \n",
      "22            LLM_Data Scientist/Data Analyst          Excellent Opportunity   \n",
      "23                             Data Scientist                     hireskills   \n",
      "\n",
      "      Location                       Salary  \n",
      "0    Bengaluru   ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1   Coimbatore          ₹4L (Employer Est.)  \n",
      "2       Remote         ₹10T (Employer Est.)  \n",
      "3        India  ₹15L - ₹41L (Employer Est.)  \n",
      "4       Remote   ₹7L - ₹12L (Employer Est.)  \n",
      "5       Remote   ₹5L - ₹19L (Employer Est.)  \n",
      "6    Bengaluru  ₹10L - ₹12L (Employer Est.)  \n",
      "7       Remote    ₹3L - ₹4L (Employer Est.)  \n",
      "8        India          ₹4L (Employer Est.)  \n",
      "9       Remote  ₹10L - ₹15L (Employer Est.)  \n",
      "10   Hyderābād  ₹12T - ₹18T (Employer Est.)  \n",
      "11   Hyderābād  ₹50L - ₹74L (Employer Est.)  \n",
      "12      Remote  ₹15L - ₹30L (Employer Est.)  \n",
      "13   Bengaluru  ₹15L - ₹41L (Employer Est.)  \n",
      "14      Remote  ₹3L - ₹10L (Glassdoor Est.)  \n",
      "15       India   ₹6L - ₹18L (Employer Est.)  \n",
      "16      Remote         ₹20T (Employer Est.)  \n",
      "17      Mumbai  ₹14L - ₹41L (Employer Est.)  \n",
      "18      Remote   ₹6L - ₹15L (Employer Est.)  \n",
      "19   Bengaluru  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "20     Chennai   ₹8T - ₹10T (Employer Est.)  \n",
      "21       India   ₹7L - ₹8L (Glassdoor Est.)  \n",
      "22      Remote   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "23      Mumbai          ₹8L (Employer Est.)  \n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Function to clean up text\n",
    "def clean_text(text):\n",
    "    return text.replace('\\u20B9', '₹').replace('\\u00A0', ' ').replace('Â', '').strip()\n",
    "\n",
    "# Extract job titles\n",
    "job_titles = [clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y')]\n",
    "\n",
    "# Extract company names\n",
    "company_names = [clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE')]\n",
    "\n",
    "# Extract locations\n",
    "locations = [clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x')]\n",
    "\n",
    "# Extract salaries\n",
    "salaries = [clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J')]\n",
    "\n",
    "# Print extracted data for verification\n",
    "print(\"Job Titles:\", job_titles)\n",
    "print(\"Company Names:\", company_names)\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Salaries:\", salaries)\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "print(\"Data saved to glassdoor_job_listings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "262612f8-da8f-4de8-b358-bc3f520c641b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary Elements Raw: ['₹2L - ₹6L (Glassdoor Est.)', '₹4L (Employer Est.)', '₹10T (Employer Est.)', '₹15L - ₹41L (Employer Est.)', '₹7L - ₹12L (Employer Est.)', '₹5L - ₹19L (Employer Est.)', '₹10L - ₹12L (Employer Est.)', '₹3L - ₹4L (Employer Est.)', '₹12T - ₹18T (Employer Est.)', '₹4L (Employer Est.)', '₹10L - ₹15L (Employer Est.)', '₹50L - ₹74L (Employer Est.)', '₹15L - ₹41L (Employer Est.)', '₹15L - ₹30L (Employer Est.)', '₹14L - ₹41L (Employer Est.)', '₹6L - ₹18L (Employer Est.)', '₹20T (Employer Est.)', '₹6L - ₹15L (Employer Est.)', '₹8T - ₹10T (Employer Est.)', '₹3L - ₹8L (Glassdoor Est.)', '₹7L - ₹8L (Glassdoor Est.)', '₹8T - ₹10T (Employer Est.)', '₹7L - ₹10L (Glassdoor Est.)', '₹20L - ₹30L (Employer Est.)']\n",
      "Job Titles: ['Data Scientist', 'NLP Project Manager', 'Data Scientist', 'Data Scientist - Junior (#40500)', 'Data Scientist', 'Data Scientist', 'Data Scientist, University Graduate, 2025', 'Data Scientist - immediate joiner', 'Data Scientist', 'Principal Data Analytics', 'Data Scientist', 'Data Scientist Intern', 'Junior Data Scientist', 'Data Science Intern', 'Data Scientist', 'Data Scientist', 'Data Scientist II', 'Junior Data Scientist', 'Python Data Scientist', 'Data Scientist', 'LLM_Data Scientist/Data Analyst', 'Data Scientist', 'Data Scientist Intern', 'Data Scientist', 'Data Science & ML Intern', 'Data Scientist', 'Data Scientist', 'Data Analyst', 'Data Scientist', 'Data Scientist- Pune, Gurgaon']\n",
      "Company Names: ['Flipkart3.8', 'objectways', 'Blackcoffer (OPC) Pvt. Ltd4.1', 'Infocepts3.5', 'Smart Capital Center3.7', 'Laurate LLC', 'Google4.3', 'Nithminds Private limited', 'Accusaga', 'Zelis3.8', 'Datacorns LLC', 'SoulPage IT Solutions4.5', 'Ray Business Technologies', 'Ecowiser5.0', 'Impresario Global', 'HealthPlix Technologies', 'Indeed4.0', 'Cravita Technologies India4.4', 'Act2hire', 'Larsen & Toubro3.4', 'Excellent Opportunity', 'Adhiran Infotech', 'Testcore Solutions', 'hireskills', 'Trekato Pvt. Ltd.', 'Provenir Inc.2.9', 'Exponentia.ai4.6', '11X Company', 'Kinara Capital4.3', 'Nanostuffs Technologies Pvt. Ltd.', 'Flipkart3.8']\n",
      "Locations: ['Bengaluru', 'Coimbatore', 'Remote', 'India', 'Remote', 'Remote', 'Bengaluru', 'Remote', 'India', 'Hyderābād', 'Remote', 'Hyderābād', 'Hyderābād', 'Remote', 'Remote', 'Bengaluru', 'Remote', 'India', 'Remote', 'Mumbai', 'Remote', 'Chennai', 'India', 'Mumbai', 'Chennai', 'Bengaluru', 'Mumbai', 'Remote', 'Bengaluru', 'India']\n",
      "Salaries: ['₹2L - ₹6L (Glassdoor Est.)', '₹4L (Employer Est.)', '₹10T (Employer Est.)', '₹15L - ₹41L (Employer Est.)', '₹7L - ₹12L (Employer Est.)', '₹5L - ₹19L (Employer Est.)', '₹10L - ₹12L (Employer Est.)', '₹3L - ₹4L (Employer Est.)', '₹12T - ₹18T (Employer Est.)', '₹4L (Employer Est.)', '₹10L - ₹15L (Employer Est.)', '₹50L - ₹74L (Employer Est.)', '₹15L - ₹41L (Employer Est.)', '₹15L - ₹30L (Employer Est.)', '₹14L - ₹41L (Employer Est.)', '₹6L - ₹18L (Employer Est.)', '₹20T (Employer Est.)', '₹6L - ₹15L (Employer Est.)', '₹8T - ₹10T (Employer Est.)', '₹3L - ₹8L (Glassdoor Est.)', '₹7L - ₹8L (Glassdoor Est.)', '₹8T - ₹10T (Employer Est.)', '₹7L - ₹10L (Glassdoor Est.)', '₹20L - ₹30L (Employer Est.)']\n",
      "                                    Job Title                        Company  \\\n",
      "0                              Data Scientist                    Flipkart3.8   \n",
      "1                         NLP Project Manager                     objectways   \n",
      "2                              Data Scientist  Blackcoffer (OPC) Pvt. Ltd4.1   \n",
      "3            Data Scientist - Junior (#40500)                   Infocepts3.5   \n",
      "4                              Data Scientist        Smart Capital Center3.7   \n",
      "5                              Data Scientist                    Laurate LLC   \n",
      "6   Data Scientist, University Graduate, 2025                      Google4.3   \n",
      "7           Data Scientist - immediate joiner      Nithminds Private limited   \n",
      "8                              Data Scientist                       Accusaga   \n",
      "9                    Principal Data Analytics                       Zelis3.8   \n",
      "10                             Data Scientist                  Datacorns LLC   \n",
      "11                      Data Scientist Intern       SoulPage IT Solutions4.5   \n",
      "12                      Junior Data Scientist      Ray Business Technologies   \n",
      "13                        Data Science Intern                    Ecowiser5.0   \n",
      "14                             Data Scientist              Impresario Global   \n",
      "15                             Data Scientist        HealthPlix Technologies   \n",
      "16                          Data Scientist II                      Indeed4.0   \n",
      "17                      Junior Data Scientist  Cravita Technologies India4.4   \n",
      "18                      Python Data Scientist                       Act2hire   \n",
      "19                             Data Scientist             Larsen & Toubro3.4   \n",
      "20            LLM_Data Scientist/Data Analyst          Excellent Opportunity   \n",
      "21                             Data Scientist               Adhiran Infotech   \n",
      "22                      Data Scientist Intern             Testcore Solutions   \n",
      "23                             Data Scientist                     hireskills   \n",
      "\n",
      "       Location                       Salary  \n",
      "0     Bengaluru   ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1    Coimbatore          ₹4L (Employer Est.)  \n",
      "2        Remote         ₹10T (Employer Est.)  \n",
      "3         India  ₹15L - ₹41L (Employer Est.)  \n",
      "4        Remote   ₹7L - ₹12L (Employer Est.)  \n",
      "5        Remote   ₹5L - ₹19L (Employer Est.)  \n",
      "6     Bengaluru  ₹10L - ₹12L (Employer Est.)  \n",
      "7        Remote    ₹3L - ₹4L (Employer Est.)  \n",
      "8         India  ₹12T - ₹18T (Employer Est.)  \n",
      "9   Hyderābād          ₹4L (Employer Est.)  \n",
      "10       Remote  ₹10L - ₹15L (Employer Est.)  \n",
      "11  Hyderābād  ₹50L - ₹74L (Employer Est.)  \n",
      "12  Hyderābād  ₹15L - ₹41L (Employer Est.)  \n",
      "13       Remote  ₹15L - ₹30L (Employer Est.)  \n",
      "14       Remote  ₹14L - ₹41L (Employer Est.)  \n",
      "15    Bengaluru   ₹6L - ₹18L (Employer Est.)  \n",
      "16       Remote         ₹20T (Employer Est.)  \n",
      "17        India   ₹6L - ₹15L (Employer Est.)  \n",
      "18       Remote   ₹8T - ₹10T (Employer Est.)  \n",
      "19       Mumbai   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "20       Remote   ₹7L - ₹8L (Glassdoor Est.)  \n",
      "21      Chennai   ₹8T - ₹10T (Employer Est.)  \n",
      "22        India  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "23       Mumbai  ₹20L - ₹30L (Employer Est.)  \n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Function to clean up text and normalize\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).replace('Â', '').strip()\n",
    "\n",
    "# Extract job titles\n",
    "job_titles = [clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y')]\n",
    "\n",
    "# Extract company names\n",
    "company_names = [clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE')]\n",
    "\n",
    "# Extract locations\n",
    "locations = [clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x')]\n",
    "\n",
    "# Extract salaries\n",
    "salaries = [clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J')]\n",
    "\n",
    "# Print raw salary elements for debugging\n",
    "salary_elements = [clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J')]\n",
    "print(\"Salary Elements Raw:\", salary_elements)\n",
    "\n",
    "# Print extracted data for verification\n",
    "print(\"Job Titles:\", job_titles)\n",
    "print(\"Company Names:\", company_names)\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Salaries:\", salaries)\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d140507-c60f-4eb6-8454-49bfa48f73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Get the page source and parse it\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Function to clean up text and normalize\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).replace('Â', '').strip()\n",
    "\n",
    "# Extract job titles\n",
    "job_titles = [clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y')]\n",
    "\n",
    "# Extract company names\n",
    "company_names = [clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE')]\n",
    "\n",
    "# Extract locations\n",
    "locations = [clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x')]\n",
    "\n",
    "# Extract salaries\n",
    "salaries = [clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J')]\n",
    "\n",
    "# Print raw salary elements for debugging\n",
    "salary_elements = [clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J')]\n",
    "print(\"Salary Elements Raw:\", salary_elements)\n",
    "\n",
    "# Print extracted data for verification\n",
    "print(\"Job Titles:\", job_titles)\n",
    "print(\"Company Names:\", company_names)\n",
    "print(\"Locations:\", locations)\n",
    "print(\"Salaries:\", salaries)\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12fbbe00-049b-44a5-905d-2ebe2f522fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjkad\\AppData\\Local\\Temp\\ipykernel_16012\\1012313268.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  next_page = soup.find('a', text='Next')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Job Title                        Company  \\\n",
      "0                              Data Scientist                    Flipkart3.8   \n",
      "1                         NLP Project Manager                     objectways   \n",
      "2                              Data Scientist  Blackcoffer (OPC) Pvt. Ltd4.1   \n",
      "3            Data Scientist - Junior (#40500)                   Infocepts3.5   \n",
      "4                              Data Scientist        Smart Capital Center3.7   \n",
      "5                              Data Scientist                    Laurate LLC   \n",
      "6   Data Scientist, University Graduate, 2025                      Google4.3   \n",
      "7           Data Scientist - immediate joiner      Nithminds Private limited   \n",
      "8                              Data Scientist                       Accusaga   \n",
      "9                              Data Scientist                  Datacorns LLC   \n",
      "10                      Data Scientist Intern       SoulPage IT Solutions4.5   \n",
      "11                      Junior Data Scientist      Ray Business Technologies   \n",
      "12                        Data Science Intern                    Ecowiser5.0   \n",
      "13                             Data Scientist              Impresario Global   \n",
      "14                             Data Scientist        HealthPlix Technologies   \n",
      "15                          Data Scientist II                      Indeed4.0   \n",
      "16                      Junior Data Scientist  Cravita Technologies India4.4   \n",
      "17                      Python Data Scientist                       Act2hire   \n",
      "18                      python data scientist                       ACT2HIRE   \n",
      "19                             Data Scientist             Larsen & Toubro3.4   \n",
      "20            LLM_Data Scientist/Data Analyst          Excellent Opportunity   \n",
      "21                             Data Scientist               Adhiran Infotech   \n",
      "22                      Data Scientist Intern             Testcore Solutions   \n",
      "23                             Data Scientist                     hireskills   \n",
      "24                   Data Science & ML Intern              Trekato Pvt. Ltd.   \n",
      "\n",
      "       Location                       Salary  \n",
      "0     Bengaluru   ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1    Coimbatore          ₹4L (Employer Est.)  \n",
      "2        Remote         ₹10T (Employer Est.)  \n",
      "3         India  ₹15L - ₹41L (Employer Est.)  \n",
      "4        Remote   ₹7L - ₹12L (Employer Est.)  \n",
      "5        Remote   ₹5L - ₹19L (Employer Est.)  \n",
      "6     Bengaluru  ₹10L - ₹12L (Employer Est.)  \n",
      "7        Remote    ₹3L - ₹4L (Employer Est.)  \n",
      "8         India  ₹12T - ₹18T (Employer Est.)  \n",
      "9        Remote          ₹4L (Employer Est.)  \n",
      "10  Hyderābād  ₹10L - ₹15L (Employer Est.)  \n",
      "11  Hyderābād  ₹50L - ₹74L (Employer Est.)  \n",
      "12       Remote  ₹15L - ₹41L (Employer Est.)  \n",
      "13       Remote  ₹15L - ₹41L (Employer Est.)  \n",
      "14    Bengaluru  ₹15L - ₹30L (Employer Est.)  \n",
      "15       Remote  ₹14L - ₹41L (Employer Est.)  \n",
      "16        India   ₹6L - ₹18L (Employer Est.)  \n",
      "17       Remote         ₹20T (Employer Est.)  \n",
      "18       Remote   ₹6L - ₹15L (Employer Est.)  \n",
      "19       Mumbai   ₹8T - ₹10T (Employer Est.)  \n",
      "20       Remote   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "21      Chennai   ₹7L - ₹8L (Glassdoor Est.)  \n",
      "22        India   ₹8T - ₹10T (Employer Est.)  \n",
      "23       Mumbai  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "24      Chennai  ₹20L - ₹30L (Employer Est.)  \n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist&page=1'\n",
    "job_titles = []\n",
    "company_names = []\n",
    "locations = []\n",
    "salaries = []\n",
    "\n",
    "while True:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract job titles\n",
    "    job_titles.extend(clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y'))\n",
    "    \n",
    "    # Extract company names\n",
    "    company_names.extend(clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE'))\n",
    "    \n",
    "    # Extract locations\n",
    "    locations.extend(clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x'))\n",
    "    \n",
    "    # Extract salaries\n",
    "    salaries.extend(clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J'))\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    next_page = soup.find('a', text='Next')\n",
    "    if next_page:\n",
    "        url = next_page['href']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52ba084b-8cfd-4337-a354-996ee124b047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Job Title                        Company  \\\n",
      "0                              Data Scientist                    Flipkart3.8   \n",
      "1                         NLP Project Manager                     objectways   \n",
      "2                              Data Scientist  Blackcoffer (OPC) Pvt. Ltd4.1   \n",
      "3            Data Scientist - Junior (#40500)                   Infocepts3.5   \n",
      "4                              Data Scientist        Smart Capital Center3.7   \n",
      "5                              Data Scientist                    Laurate LLC   \n",
      "6   Data Scientist, University Graduate, 2025                      Google4.3   \n",
      "7                              Data Scientist                  Datacorns LLC   \n",
      "8           Data Scientist - immediate joiner      Nithminds Private limited   \n",
      "9                              Data Scientist                       Accusaga   \n",
      "10                        Data Science Intern                    Ecowiser5.0   \n",
      "11                      Data Scientist Intern       SoulPage IT Solutions4.5   \n",
      "12                      Junior Data Scientist      Ray Business Technologies   \n",
      "13                             Data Scientist              Impresario Global   \n",
      "14                             Data Scientist        HealthPlix Technologies   \n",
      "15                          Data Scientist II                      Indeed4.0   \n",
      "16                      Junior Data Scientist  Cravita Technologies India4.4   \n",
      "17                      Python Data Scientist                       Act2hire   \n",
      "18                      python data scientist                       ACT2HIRE   \n",
      "19                             Data Scientist             Larsen & Toubro3.4   \n",
      "20            LLM_Data Scientist/Data Analyst          Excellent Opportunity   \n",
      "21                             Data Scientist               Adhiran Infotech   \n",
      "22                      Data Scientist Intern             Testcore Solutions   \n",
      "23                             Data Scientist                     hireskills   \n",
      "24                   Data Science & ML Intern              Trekato Pvt. Ltd.   \n",
      "\n",
      "       Location                       Salary  \n",
      "0     Bengaluru   ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1    Coimbatore          ₹4L (Employer Est.)  \n",
      "2        Remote         ₹10T (Employer Est.)  \n",
      "3         India  ₹15L - ₹41L (Employer Est.)  \n",
      "4        Remote  ₹10L - ₹12L (Employer Est.)  \n",
      "5        Remote   ₹7L - ₹12L (Employer Est.)  \n",
      "6     Bengaluru   ₹5L - ₹19L (Employer Est.)  \n",
      "7        Remote  ₹12T - ₹18T (Employer Est.)  \n",
      "8        Remote    ₹3L - ₹4L (Employer Est.)  \n",
      "9         India          ₹4L (Employer Est.)  \n",
      "10       Remote  ₹10L - ₹15L (Employer Est.)  \n",
      "11  Hyderābād  ₹50L - ₹74L (Employer Est.)  \n",
      "12  Hyderābād  ₹15L - ₹41L (Employer Est.)  \n",
      "13       Remote  ₹15L - ₹41L (Employer Est.)  \n",
      "14    Bengaluru  ₹15L - ₹30L (Employer Est.)  \n",
      "15       Remote  ₹14L - ₹41L (Employer Est.)  \n",
      "16        India   ₹6L - ₹18L (Employer Est.)  \n",
      "17       Remote         ₹20T (Employer Est.)  \n",
      "18       Remote   ₹6L - ₹15L (Employer Est.)  \n",
      "19       Mumbai   ₹8T - ₹10T (Employer Est.)  \n",
      "20       Remote   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "21      Chennai   ₹8T - ₹10T (Employer Est.)  \n",
      "22        India  ₹20L - ₹30L (Employer Est.)  \n",
      "23       Mumbai  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "24      Chennai          ₹8L (Employer Est.)  \n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to clean up text and normalize\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).replace('Â', '').strip()\n",
    "\n",
    "# Lists to store data\n",
    "job_titles = []\n",
    "company_names = []\n",
    "locations = []\n",
    "salaries = []\n",
    "\n",
    "while True:\n",
    "    # Get the page source and parse it\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract data from the current page\n",
    "    job_titles.extend(clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y'))\n",
    "    company_names.extend(clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE'))\n",
    "    locations.extend(clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x'))\n",
    "    salaries.extend(clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J'))\n",
    "    \n",
    "    # Attempt to find and click the \"Show more jobs\" button\n",
    "    try:\n",
    "        show_more_button = driver.find_element(By.CLASS_NAME, 'gd-btn-mkt')\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "        time.sleep(5)  # Wait for new jobs to load\n",
    "    except:\n",
    "        break  # Exit the loop if no more pages are found\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d6662e3-bf44-43c8-a07f-0e97eb9ba822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Job Title                        Company  \\\n",
      "0                              Data Scientist                    Flipkart3.8   \n",
      "1                         NLP Project Manager                     objectways   \n",
      "2                              Data Scientist  Blackcoffer (OPC) Pvt. Ltd4.1   \n",
      "3            Data Scientist - Junior (#40500)                   Infocepts3.5   \n",
      "4                              Data Scientist        Smart Capital Center3.7   \n",
      "5                              Data Scientist                    Laurate LLC   \n",
      "6   Data Scientist, University Graduate, 2025                      Google4.3   \n",
      "7           Data Scientist - immediate joiner      Nithminds Private limited   \n",
      "8                              Data Scientist                  Datacorns LLC   \n",
      "9                              Data Scientist                       Accusaga   \n",
      "10                        Data Science Intern                    Ecowiser5.0   \n",
      "11                      Junior Data Scientist      Ray Business Technologies   \n",
      "12                             Data Scientist              Impresario Global   \n",
      "13                      Data Scientist Intern       SoulPage IT Solutions4.5   \n",
      "14                             Data Scientist        HealthPlix Technologies   \n",
      "15                          Data Scientist II                      Indeed4.0   \n",
      "16                      Junior Data Scientist  Cravita Technologies India4.4   \n",
      "17                      Python Data Scientist                       Act2hire   \n",
      "18                             Data Scientist             Larsen & Toubro3.4   \n",
      "19                      python data scientist                       ACT2HIRE   \n",
      "20            LLM_Data Scientist/Data Analyst          Excellent Opportunity   \n",
      "21                             Data Scientist               Adhiran Infotech   \n",
      "22                      Data Scientist Intern             Testcore Solutions   \n",
      "23                               Data Analyst                    11X Company   \n",
      "24                             Data Scientist                     hireskills   \n",
      "\n",
      "       Location                       Salary  \n",
      "0     Bengaluru   ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1    Coimbatore          ₹4L (Employer Est.)  \n",
      "2        Remote         ₹10T (Employer Est.)  \n",
      "3         India  ₹15L - ₹41L (Employer Est.)  \n",
      "4        Remote   ₹7L - ₹12L (Employer Est.)  \n",
      "5        Remote  ₹10L - ₹12L (Employer Est.)  \n",
      "6     Bengaluru   ₹5L - ₹19L (Employer Est.)  \n",
      "7        Remote  ₹12T - ₹18T (Employer Est.)  \n",
      "8        Remote    ₹3L - ₹4L (Employer Est.)  \n",
      "9         India          ₹4L (Employer Est.)  \n",
      "10       Remote  ₹10L - ₹15L (Employer Est.)  \n",
      "11  Hyderābād  ₹50L - ₹74L (Employer Est.)  \n",
      "12       Remote  ₹15L - ₹41L (Employer Est.)  \n",
      "13  Hyderābād  ₹15L - ₹30L (Employer Est.)  \n",
      "14    Bengaluru  ₹15L - ₹41L (Employer Est.)  \n",
      "15       Remote  ₹14L - ₹41L (Employer Est.)  \n",
      "16        India   ₹6L - ₹18L (Employer Est.)  \n",
      "17       Remote         ₹20T (Employer Est.)  \n",
      "18       Mumbai   ₹8T - ₹10T (Employer Est.)  \n",
      "19       Remote   ₹6L - ₹15L (Employer Est.)  \n",
      "20       Remote          ₹8L (Employer Est.)  \n",
      "21      Chennai   ₹8T - ₹10T (Employer Est.)  \n",
      "22        India  ₹20L - ₹30L (Employer Est.)  \n",
      "23       Remote   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "24       Mumbai  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "Data saved to glassdoor_job_listings.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.com/Job/jobs.htm?sc.keyword=data%20scientist'\n",
    "driver.get(url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Function to clean up text and normalize\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).replace('Â', '').strip()\n",
    "\n",
    "# Lists to store data\n",
    "job_titles = []\n",
    "company_names = []\n",
    "locations = []\n",
    "salaries = []\n",
    "\n",
    "# Scroll and load more jobs\n",
    "while True:\n",
    "    # Extract data from the current page\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    job_titles.extend(clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y'))\n",
    "    company_names.extend(clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE'))\n",
    "    locations.extend(clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x'))\n",
    "    salaries.extend(clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J'))\n",
    "    \n",
    "    # Scroll to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)  # Wait for new jobs to load\n",
    "    \n",
    "    # Check if the \"Show more jobs\" button is visible and clickable\n",
    "    try:\n",
    "        show_more_button = driver.find_element(By.CLASS_NAME, 'gd-btn-mkt')\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "        time.sleep(5)  # Wait for new jobs to load\n",
    "    except:\n",
    "        break  # Exit the loop if no more jobs are found or no button is present\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cce7e4a-e22e-4942-a046-84a9d629512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjkad\\AppData\\Local\\Temp\\ipykernel_16012\\2451957586.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  next_page = soup.find('a', text='Next')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Job Title  \\\n",
      "0                              Data Scientist   \n",
      "1                              Data Scientist   \n",
      "2                              Data Scientist   \n",
      "3   Data Scientist, University Graduate, 2025   \n",
      "4                              Data Scientist   \n",
      "5                         Data Science Intern   \n",
      "6                       Junior Data Scientist   \n",
      "7                              Data Scientist   \n",
      "8                              Data Scientist   \n",
      "9                           Data Scientist II   \n",
      "10                      Python Data Scientist   \n",
      "11                             Data Scientist   \n",
      "12                      Data Scientist Intern   \n",
      "13                             Data Scientist   \n",
      "14                             Data Scientist   \n",
      "15              Data Scientist- Pune, Gurgaon   \n",
      "16                             Data Scientist   \n",
      "17                             Data Scientist   \n",
      "18                    Graduate Data Scientist   \n",
      "19            LLM Data Scientist/Data Analyst   \n",
      "20                             Data Scientist   \n",
      "21                          Sr Data Scientist   \n",
      "22                     Trainee Data Scientist   \n",
      "\n",
      "                                      Company            Location  \\\n",
      "0                                 Flipkart3.8           Bengaluru   \n",
      "1               Blackcoffer (OPC) Pvt. Ltd4.1              Remote   \n",
      "2                     Smart Capital Center3.7              Remote   \n",
      "3                                   Google4.3           Bengaluru   \n",
      "4                               Datacorns LLC              Remote   \n",
      "5                                 Ecowiser5.0              Remote   \n",
      "6                   Ray Business Technologies         Hyderābād   \n",
      "7                           Impresario Global              Remote   \n",
      "8                     HealthPlix Technologies           Bengaluru   \n",
      "9                                   Indeed4.0              Remote   \n",
      "10                                   Act2hire              Remote   \n",
      "11                         Larsen & Toubro3.4              Mumbai   \n",
      "12                         Testcore Solutions               India   \n",
      "13                                 hireskills              Mumbai   \n",
      "14  Great River Financial Services Inc (GRFS)               India   \n",
      "15          Nanostuffs Technologies Pvt. Ltd.               India   \n",
      "16                           Provenir Inc.2.9           Bengaluru   \n",
      "17                          Kinara Capital4.3           Bengaluru   \n",
      "18                                 Arcadis4.0               India   \n",
      "19                                   Act2hire              Remote   \n",
      "20                           Exponentia.ai4.6              Mumbai   \n",
      "21                                  Target4.3           Karnataka   \n",
      "22                     Techvantage Systems4.2  Thiruvananthapuram   \n",
      "\n",
      "                         Salary  \n",
      "0    ₹2L - ₹6L (Glassdoor Est.)  \n",
      "1          ₹10T (Employer Est.)  \n",
      "2   ₹10L - ₹12L (Employer Est.)  \n",
      "3   ₹12T - ₹18T (Employer Est.)  \n",
      "4     ₹3L - ₹4L (Employer Est.)  \n",
      "5           ₹4L (Employer Est.)  \n",
      "6   ₹10L - ₹15L (Employer Est.)  \n",
      "7   ₹50L - ₹74L (Employer Est.)  \n",
      "8   ₹15L - ₹41L (Employer Est.)  \n",
      "9   ₹15L - ₹30L (Employer Est.)  \n",
      "10         ₹20T (Employer Est.)  \n",
      "11   ₹6L - ₹15L (Employer Est.)  \n",
      "12          ₹8L (Employer Est.)  \n",
      "13  ₹20L - ₹30L (Employer Est.)  \n",
      "14   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "15  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "16  ₹15L - ₹26L (Employer Est.)  \n",
      "17   ₹7L - ₹8L (Glassdoor Est.)  \n",
      "18   ₹3L - ₹8L (Glassdoor Est.)  \n",
      "19  ₹4L - ₹10L (Glassdoor Est.)  \n",
      "20   ₹2L - ₹8L (Glassdoor Est.)  \n",
      "21    ₹5L - ₹9L (Employer Est.)  \n",
      "22  ₹4L - ₹10L (Glassdoor Est.)  \n",
      "Data saved to glassdoor_job_listings_1.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.co.in/Job/united-states-data-scientist-jobs-SRCH_IL.0,13_KO14,28.htm?fromAge=30'\n",
    "job_titles = []\n",
    "company_names = []\n",
    "locations = []\n",
    "salaries = []\n",
    "\n",
    "while True:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract job titles\n",
    "    job_titles.extend(clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y'))\n",
    "    \n",
    "    # Extract company names\n",
    "    company_names.extend(clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE'))\n",
    "    \n",
    "    # Extract locations\n",
    "    locations.extend(clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x'))\n",
    "    \n",
    "    # Extract salaries\n",
    "    salaries.extend(clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J'))\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    next_page = soup.find('a', text='Next')\n",
    "    if next_page:\n",
    "        url = next_page['href']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings_1.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings_1.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2a97683-1a5f-40da-b1eb-4be6c2a42a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sjkad\\AppData\\Local\\Temp\\ipykernel_16012\\3542482442.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  next_page = soup.find('a', text='Next')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Job Title                                     Company  \\\n",
      "0             DevOps Engineer                                    Apple4.2   \n",
      "1             Devops Engineer                                    Optum3.5   \n",
      "2             Devops Engineer  Rite Software Solutions & Services (IN)4.1   \n",
      "3             DevOps Engineer          Acrocede Technologies Pvt. Ltd.4.8   \n",
      "4             DevOps Engineer                                Promptora AI   \n",
      "5       DevOps (AWS) Engineer                                     Zazz3.6   \n",
      "6             DevOps Engineer                                 Experian4.1   \n",
      "7         Devops Engineer - I                            Phenom People4.0   \n",
      "8      Junior DevOps Engineer                               MyVerkoper2.9   \n",
      "9       DevOps Engineer (AWS)            Indiglobe IT Solutions Pvt. Ltd.   \n",
      "10            DevOps Engineer                                Accenture3.9   \n",
      "11  Associate DevOps Engineer                                 NTT DATA3.8   \n",
      "12        AWS DevOps Engineer                                   CRISIL3.8   \n",
      "13            Devops Engineer                                  AbhiBus2.9   \n",
      "14            DevOps Engineer                                       360Ex   \n",
      "15            Devops Engineer                            Laddu Systems4.0   \n",
      "16            DevOps Engineer                               SoCtronics3.7   \n",
      "17            Devops Engineer                Zerocode Innovations Pvt Ltd   \n",
      "18            Devops Engineer                          Gaian Solutions3.6   \n",
      "19       DevOps Engineer, PLM                                    Apple4.2   \n",
      "\n",
      "       Location                       Salary  \n",
      "0   Hyderābād   ₹5L - ₹8L (Glassdoor Est.)  \n",
      "1   Hyderābād   ₹1L - ₹3L (Glassdoor Est.)  \n",
      "2   Hyderābād   ₹3L - ₹7L (Glassdoor Est.)  \n",
      "3   Hyderābād  ₹13L - ₹15L (Employer Est.)  \n",
      "4   Hyderābād  ₹14L - ₹16L (Employer Est.)  \n",
      "5   Hyderābād  ₹7L - ₹10L (Glassdoor Est.)  \n",
      "6   Hyderābād  ₹15L - ₹18L (Employer Est.)  \n",
      "7   Hyderābād   ₹1L - ₹7L (Glassdoor Est.)  \n",
      "8         India   ₹3L - ₹7L (Glassdoor Est.)  \n",
      "9   Hyderābād   ₹4L - ₹8L (Glassdoor Est.)  \n",
      "10  Hyderābād   ₹5L - ₹6L (Glassdoor Est.)  \n",
      "11  Hyderābād   ₹6L - ₹8L (Glassdoor Est.)  \n",
      "12  Hyderābād   ₹4L - ₹16L (Employer Est.)  \n",
      "13  Hyderābād   ₹5L - ₹9L (Glassdoor Est.)  \n",
      "14  Hyderābād   ₹5L - ₹8L (Glassdoor Est.)  \n",
      "15  Hyderābād          ₹5L (Employer Est.)  \n",
      "16  Hyderābād   ₹4L - ₹8L (Glassdoor Est.)  \n",
      "17        India   ₹6L - ₹8L (Glassdoor Est.)  \n",
      "18  Hyderābād   ₹4L - ₹8L (Glassdoor Est.)  \n",
      "19  Hyderābād   ₹2L - ₹7L (Glassdoor Est.)  \n",
      "Data saved to glassdoor_job_listings_devops.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# Set up WebDriver with Service\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# Open Glassdoor job search page\n",
    "url = 'https://www.glassdoor.co.in/Job/hyderabad-india-devops-engineer-jobs-SRCH_IL.0,15_IC2865319_KO16,31.htm'\n",
    "job_titles = []\n",
    "company_names = []\n",
    "locations = []\n",
    "salaries = []\n",
    "\n",
    "while True:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Extract job titles\n",
    "    job_titles.extend(clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y'))\n",
    "    \n",
    "    # Extract company names\n",
    "    company_names.extend(clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE'))\n",
    "    \n",
    "    # Extract locations\n",
    "    locations.extend(clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x'))\n",
    "    \n",
    "    # Extract salaries\n",
    "    salaries.extend(clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J'))\n",
    "    \n",
    "    # Check if there is a next page\n",
    "    next_page = soup.find('a', text='Next')\n",
    "    if next_page:\n",
    "        url = next_page['href']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(job_titles), len(company_names), len(locations), len(salaries))\n",
    "\n",
    "job_titles = job_titles[:min_length]\n",
    "company_names = company_names[:min_length]\n",
    "locations = locations[:min_length]\n",
    "salaries = salaries[:min_length]\n",
    "\n",
    "# Store the data in a DataFrame\n",
    "job_data = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': company_names,\n",
    "    'Location': locations,\n",
    "    'Salary': salaries\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(job_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "try:\n",
    "    job_data.to_csv('glassdoor_job_listings_devops.csv', index=False)\n",
    "    print(\"Data saved to glassdoor_job_listings_devops.csv\")\n",
    "except PermissionError:\n",
    "    print(\"Permission error: Please close the CSV file if it's open.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4ce7aa79-9887-4388-a22e-836a991dd737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to glassdoor_job_listings_1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import unicodedata\n",
    "\n",
    "# Function to clean up text and normalize\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize('NFKD', text).replace('Â', '').strip()\n",
    "\n",
    "# Set up WebDriver with Service for the new URL\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "# New URL to scrape\n",
    "new_url = 'https://www.glassdoor.co.in/Job/bengaluru-india-blockchain-developer-jobs-SRCH_IL.0,15_IC2940587_KO16,36.htm'\n",
    "driver.get(new_url)\n",
    "time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "# Scrape data from the new URL\n",
    "new_job_titles = []\n",
    "new_company_names = []\n",
    "new_locations = []\n",
    "new_salaries = []\n",
    "\n",
    "while True:\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    new_job_titles.extend(clean_text(title.text.strip()) for title in soup.find_all('a', class_='JobCard_jobTitle___7I6y'))\n",
    "    new_company_names.extend(clean_text(company.text.strip()) for company in soup.find_all('div', class_='EmployerProfile_employerInfo__d8uSE'))\n",
    "    new_locations.extend(clean_text(location.text.strip()) for location in soup.find_all('div', class_='JobCard_location__rCz3x'))\n",
    "    new_salaries.extend(clean_text(salary.text.strip()) for salary in soup.find_all('div', class_='JobCard_salaryEstimate__arV5J'))\n",
    "\n",
    "    # Attempt to find and click the \"Show more jobs\" button\n",
    "    try:\n",
    "        show_more_button = driver.find_element(By.CLASS_NAME, 'gd-btn-mkt')\n",
    "        driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
    "        time.sleep(5)  # Wait for new jobs to load\n",
    "    except:\n",
    "        break  # Exit the loop if no more jobs are found or no button is present\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Ensure all lists are of the same length\n",
    "min_length = min(len(new_job_titles), len(new_company_names), len(new_locations), len(new_salaries))\n",
    "new_job_titles = new_job_titles[:min_length]\n",
    "new_company_names = new_company_names[:min_length]\n",
    "new_locations = new_locations[:min_length]\n",
    "new_salaries = new_salaries[:min_length]\n",
    "\n",
    "# Store the new data in a DataFrame\n",
    "new_data = pd.DataFrame({\n",
    "    'Job Title': new_job_titles,\n",
    "    'Company': new_company_names,\n",
    "    'Location': new_locations,\n",
    "    'Salary': new_salaries\n",
    "})\n",
    "\n",
    "# Load the existing CSV file\n",
    "existing_data = pd.read_csv('glassdoor_job_listings_1.csv')\n",
    "\n",
    "# Append new data to existing data\n",
    "updated_data = pd.concat([existing_data, new_data], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "updated_data.to_csv('glassdoor_job_listings_1.csv', index=False)\n",
    "print(\"Updated data saved to glassdoor_job_listings_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f02174-c0fd-4904-ad1f-a366ca1ec0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
